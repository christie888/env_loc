{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "#from datetime import *\n",
    "\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 18\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Seaborn for visualization\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imputing missing values and scaling values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV,train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error,recall_score,max_error,roc_curve, accuracy_score,confusion_matrix,r2_score,f1_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>new_tsp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>light</th>\n",
       "      <th>weekday</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>location_no</th>\n",
       "      <th>floor_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corridor1F</td>\n",
       "      <td>2019-07-07 15:40:00</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>66.868421</td>\n",
       "      <td>1006.945919</td>\n",
       "      <td>17.400541</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Corridor1F</td>\n",
       "      <td>2019-07-07 16:00:00</td>\n",
       "      <td>24.315789</td>\n",
       "      <td>65.078947</td>\n",
       "      <td>1007.157280</td>\n",
       "      <td>11.833834</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corridor1F</td>\n",
       "      <td>2019-07-07 16:20:00</td>\n",
       "      <td>24.888889</td>\n",
       "      <td>64.111111</td>\n",
       "      <td>1008.000752</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corridor1F</td>\n",
       "      <td>2019-07-07 16:40:00</td>\n",
       "      <td>24.647059</td>\n",
       "      <td>63.823529</td>\n",
       "      <td>1007.578824</td>\n",
       "      <td>6.576210</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corridor1F</td>\n",
       "      <td>2019-07-07 17:00:00</td>\n",
       "      <td>24.650000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1006.785398</td>\n",
       "      <td>14.770270</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67304</th>\n",
       "      <td>ElevatorHallB2F</td>\n",
       "      <td>2020-12-12 22:20:00</td>\n",
       "      <td>23.197467</td>\n",
       "      <td>33.110733</td>\n",
       "      <td>1008.196202</td>\n",
       "      <td>751.277457</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67305</th>\n",
       "      <td>ElevatorHallB2F</td>\n",
       "      <td>2020-12-12 22:40:00</td>\n",
       "      <td>23.234640</td>\n",
       "      <td>32.984988</td>\n",
       "      <td>1008.232075</td>\n",
       "      <td>751.277457</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67306</th>\n",
       "      <td>ElevatorHallB2F</td>\n",
       "      <td>2020-12-12 23:00:00</td>\n",
       "      <td>23.375154</td>\n",
       "      <td>32.693465</td>\n",
       "      <td>1008.280934</td>\n",
       "      <td>751.277457</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67307</th>\n",
       "      <td>ElevatorHallB2F</td>\n",
       "      <td>2020-12-12 23:20:00</td>\n",
       "      <td>23.292311</td>\n",
       "      <td>32.927597</td>\n",
       "      <td>1008.315396</td>\n",
       "      <td>751.277457</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67308</th>\n",
       "      <td>ElevatorHallB2F</td>\n",
       "      <td>2020-12-12 23:40:00</td>\n",
       "      <td>23.083156</td>\n",
       "      <td>33.440045</td>\n",
       "      <td>1008.395679</td>\n",
       "      <td>751.277457</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67309 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              location              new_tsp  temperature   humidity  \\\n",
       "0           Corridor1F  2019-07-07 15:40:00    24.000000  66.868421   \n",
       "1           Corridor1F  2019-07-07 16:00:00    24.315789  65.078947   \n",
       "2           Corridor1F  2019-07-07 16:20:00    24.888889  64.111111   \n",
       "3           Corridor1F  2019-07-07 16:40:00    24.647059  63.823529   \n",
       "4           Corridor1F  2019-07-07 17:00:00    24.650000  64.000000   \n",
       "...                ...                  ...          ...        ...   \n",
       "67304  ElevatorHallB2F  2020-12-12 22:20:00    23.197467  33.110733   \n",
       "67305  ElevatorHallB2F  2020-12-12 22:40:00    23.234640  32.984988   \n",
       "67306  ElevatorHallB2F  2020-12-12 23:00:00    23.375154  32.693465   \n",
       "67307  ElevatorHallB2F  2020-12-12 23:20:00    23.292311  32.927597   \n",
       "67308  ElevatorHallB2F  2020-12-12 23:40:00    23.083156  33.440045   \n",
       "\n",
       "          pressure       light  weekday  quarter  month  hour  day  \\\n",
       "0      1006.945919   17.400541        7        3      7    15    7   \n",
       "1      1007.157280   11.833834        7        3      7    16    7   \n",
       "2      1008.000752    0.486400        7        3      7    16    7   \n",
       "3      1007.578824    6.576210        7        3      7    16    7   \n",
       "4      1006.785398   14.770270        7        3      7    17    7   \n",
       "...            ...         ...      ...      ...    ...   ...  ...   \n",
       "67304  1008.196202  751.277457        6        4     12    22   12   \n",
       "67305  1008.232075  751.277457        6        4     12    22   12   \n",
       "67306  1008.280934  751.277457        6        4     12    23   12   \n",
       "67307  1008.315396  751.277457        6        4     12    23   12   \n",
       "67308  1008.395679  751.277457        6        4     12    23   12   \n",
       "\n",
       "       location_no  floor_no  \n",
       "0                6         2  \n",
       "1                6         2  \n",
       "2                6         2  \n",
       "3                6         2  \n",
       "4                6         2  \n",
       "...            ...       ...  \n",
       "67304            1         0  \n",
       "67305            1         0  \n",
       "67306            1         0  \n",
       "67307            1         0  \n",
       "67308            1         0  \n",
       "\n",
       "[67309 rows x 13 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "smaple='20m'\n",
    "data_file='allData_resample_'+smaple\n",
    "#allData_resample_15m\n",
    "pre_targets='location_no'#'floor_no'#\n",
    "\n",
    "df=pd.read_csv('DB/new_data/'+data_file+'.csv')\n",
    "\n",
    "# location_floor_map = {'ElevatorHall1F': 2, 'ElevatorHallB2F':0, 'ElevatorHall3F':4, 'CorridorB1F':1,\n",
    "#  'Corridor1F':2, 'Corridor3F':4,'Corridor2F':3, 'ElevatorHall2F':3, 'CorridorB2F':0,\n",
    "#  'ElevatorHallB1F':1}\n",
    "# df['floor_no'] = df['location'].map(location_floor_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_allData_resample_20m_location_no\n",
      "DB/result/sk_allData_resample_20m_location_nowith_light.csv\n",
      "file not extis\n",
      "Training Feature Size:  (47116, 10)\n",
      "Testing Feature Size:   (20193, 10)\n",
      "Training Labels Size:   (47116,)\n",
      "Testing Labels Size:    (20193,)\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "1     3112\n",
      "9     3067\n",
      "5     2510\n",
      "10    2464\n",
      "4     1999\n",
      "7     1851\n",
      "8     1796\n",
      "6     1754\n",
      "2     1250\n",
      "3      390\n",
      "dtype: int64\n",
      "0\n",
      "['new_tsp' 'temperature' 'humidity' 'pressure' 'light' 'weekday' 'quarter'\n",
      " 'month' 'hour' 'day']\n"
     ]
    }
   ],
   "source": [
    "# Save the no scores, training, and testing data\n",
    "# no_location =pd.read_csv('DB/new_data/no_location.csv')\n",
    "\n",
    "targets = df[pre_targets]\n",
    "#features =df.drop(columns={'location','location_no','floor_no','light'})\n",
    "features =df.drop(columns={'location','location_no','floor_no'})\n",
    "# Split into 70% training and 30% testing set\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, targets, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "model_type=\"sk\"\n",
    "resultfilename=model_type+'_'+data_file+'_'+pre_targets\n",
    "print(resultfilename)\n",
    "filepath='DB/result/'+resultfilename+'with_light.csv'\n",
    "print(filepath)\n",
    "if path.exists(filepath):\n",
    "    print('yes')\n",
    "    result_pd=pd.read_csv(filepath)\n",
    "else: \n",
    "    print('file not extis')\n",
    "    result_pd=pd.DataFrame()\n",
    "\n",
    "\n",
    "# train_features=cudf.read_csv('DB/floor_data/training_features.csv')\n",
    "# test_features=cudf.read_csv('DB/floor_data/testing_features.csv')\n",
    "# train_labels=cudf.read_csv('DB/floor_data/training_labels.csv')\n",
    "# test_labels=cudf.read_csv('DB/floor_data/testing_labels.csv')\n",
    "\n",
    "# train_features=pd.read_csv('DB/new_data/training_features.csv')\n",
    "# test_features=pd.read_csv('DB/new_data/testing_features.csv')\n",
    "# train_labels=pd.read_csv('DB/new_data/training_labels.csv')\n",
    "# test_labels=pd.read_csv('DB/new_data/testing_labels.csv')\n",
    "\n",
    "# #no_location =pd.read_csv('DB/data_fill/no_location.csv')\n",
    "# train_features=pd.read_csv('DB/data_fill/training_features.csv')\n",
    "# test_features=pd.read_csv('DB/data_fill/testing_features.csv')\n",
    "# train_labels=pd.read_csv('DB/data_fill/training_labels.csv')\n",
    "# test_labels=pd.read_csv('DB/data_fill/testing_labels.csv')\n",
    "\n",
    "# Display sizes of data\n",
    "print('Training Feature Size: ', train_features.shape)\n",
    "print('Testing Feature Size:  ', test_features.shape)\n",
    "print('Training Labels Size:  ', train_labels.shape)\n",
    "print('Testing Labels Size:   ', test_labels.shape)\n",
    "print(np.unique(train_labels))\n",
    "print(pd.value_counts(test_labels.values))\n",
    "\n",
    "print(test_labels.isnull().sum())\n",
    "result_pd['origin']=test_labels.values\n",
    "\n",
    "print(train_features.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training features:  0\n",
      "Missing values in testing features:   0\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Train on the training features\n",
    "imputer.fit(train_features.drop('new_tsp', axis=1))\n",
    "\n",
    "# Transform both training data and testing data\n",
    "X = imputer.transform(train_features.drop('new_tsp', axis=1))\n",
    "X_test = imputer.transform(test_features.drop('new_tsp', axis=1))\n",
    "print('Missing values in training features: ', np.sum(np.isnan(X)))\n",
    "print('Missing values in testing features:  ', np.sum(np.isnan(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GaussianNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-262cd46ffa5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of mislabeled points out of a total %d points : %d\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GaussianNB' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# Fit on the training data\n",
    "scaler.fit(X)\n",
    "# Transform both the training and testing data\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to one-dimensional array (vector)\n",
    "y = np.array(train_labels).reshape((-1, ))\n",
    "y_test = np.array(test_labels).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "\n",
    "Support Vector Machine Regression\n",
    "\n",
    "Random Forest Regression\n",
    "\n",
    "Gradient Boosting Regression\n",
    "\n",
    "K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mean absolute error    \n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(abs(y_true - y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def addToResult(result_pd,pred,model_name):\n",
    "    #global re_pd\n",
    "    #print(pred_re.type)\n",
    "    #pred_re=pred_re.set_index(name=model_name)\n",
    "    #print(pred_re.columns)\n",
    "    #pred_re.columns=[model_name]\n",
    "    pred=pd.DataFrame({model_name:pred})\n",
    "    re_pd= pd.concat([result_pd,pred],axis=1,ignore_index=True)\n",
    "    return re_pd\n",
    "\n",
    "def pro_pred(y_pred):\n",
    "    propre=np.round(y_pred)\n",
    "    return propre\n",
    "\n",
    "def make_confusion_matrix(y_test, model_pred):\n",
    "    cf_m = confusion_matrix(y_test, model_pred)\n",
    "    return cf_m\n",
    "\n",
    "def fit_and_predict(model,filename):\n",
    "    global y_test\n",
    "    global X_test\n",
    "    global X\n",
    "    global y\n",
    "    # Train the model\n",
    "    model.fit(X, y)\n",
    "    # Make predictions and evalute\n",
    "    model_pred = model.predict(X_test)\n",
    "    model_pred=pro_pred(model_pred)\n",
    "    \n",
    "    filename = 'stored_model/'+filename+'.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    return model_pred\n",
    "\n",
    "def fit_and_predict_pred(model,filename):\n",
    "    global y_test\n",
    "    global X_test\n",
    "    global X\n",
    "    global y\n",
    "    model.fit(X, y)\n",
    "    #y_score = model.fit(X, y,probability=True).decision_function(X_test)\n",
    "    #print(y_score.shape)\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "    model_pred = model.predict(X_test)\n",
    "    model_pred=pro_pred(model_pred)\n",
    "    print(probabilities)\n",
    "    #y_score = svm.fit(X_train, y_train).decision_function(X_test)\n",
    "    print(model_pred, y_test)\n",
    "    print(train_labels.unique())\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probabilities[:,1],pos_label=train_labels.unique())\n",
    "    return fpr, tpr, thresholds \n",
    "    \n",
    "def evaluate(y_test, model_pred):  \n",
    "    #model_pred=pro_pred(model_pred)\n",
    "    #model_mae = mean_absolute_error(y_test.astype(np.float32), model_pred.astype(np.float32))\n",
    "    model_mae = mean_absolute_error(y_test, model_pred)\n",
    "    model_mse = mean_squared_error(y_test, model_pred)\n",
    "    model_r2_score= r2_score(y_test, model_pred)\n",
    "    return model_mae, model_mse,model_r2_score\n",
    "\n",
    "\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def fit_and_evaluate(model,filename):\n",
    "    # Train the model\n",
    "    model.fit(X, y)\n",
    "    # Make predictions and evalute\n",
    "    model_pred = model.predict(X_test)\n",
    "    model_pred=pro_pred(model_pred)\n",
    "    #print(\"test value size...\", pd.value_counts(y_test))\n",
    "    #print(\"predicted value size...\", pd.value_counts(model_pred))\n",
    "    model_mae = mae(y_test, model_pred)\n",
    "    model_mse = mse(y_test, model_pred)\n",
    "    # Compute confusion matrix\n",
    "    #print(cnf_matrix)\n",
    "    model_r2_score= r2_score(y_test, model_pred)\n",
    "    model_max_error= max_error(y_test, model_pred)\n",
    "    print(model_pred)\n",
    "    # save the model to disk\n",
    "    filename = 'stored_model/'+filename+'.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    return model_mae,model_mse,model_r2_score,model_max_error, model_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20188</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20189</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20193 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin\n",
       "0           7\n",
       "1          10\n",
       "2           5\n",
       "3           4\n",
       "4           5\n",
       "...       ...\n",
       "20188       1\n",
       "20189       8\n",
       "20190      10\n",
       "20191       9\n",
       "20192       7\n",
       "\n",
       "[20193 rows x 1 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result_pd=addToResult(result_pd,test_labels,'origin')\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20193,)\n",
      "CPU times: user 2.48 s, sys: 0 ns, total: 2.48 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "adb = AdaBoostClassifier()\n",
    "\n",
    "adb_pred= fit_and_predict(adb,'adb_sk')\n",
    "#lr_mae,lr_mse,lr_r2_score=evaluate(y_test, lr_pred)\n",
    "#fpr, tpr, thresholds =fit_and_predict_pred(adb,'adb_sk')\n",
    "#lr_mae,lr_mse,lr_r2_score,lr_max_error,lr_pred = fit_and_evaluate(lr,'lr')\n",
    "t1 = time()\n",
    "adb_t=t1-t0\n",
    "\n",
    "print(adb_pred.shape)\n",
    "result_pd['adb']=adb_pred\n",
    "#result_pd\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 20193 points : 15269, accuracy: 0.24\n",
      "Number of mislabeled points out of a total 20193 points : 15269\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>adb</th>\n",
       "      <th>gnb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20188</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20189</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20193 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin  adb  gnb\n",
       "0           7    9    4\n",
       "1          10    6    7\n",
       "2           5   10    5\n",
       "3           4    4    2\n",
       "4           5    9    5\n",
       "...       ...  ...  ...\n",
       "20188       1    2    2\n",
       "20189       8    8    7\n",
       "20190      10    6    6\n",
       "20191       9    4    6\n",
       "20192       7    7    6\n",
       "\n",
       "[20193 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "#clf = DecisionTreeClassifier(random_state=0)\n",
    "gnb_pred = fit_and_predict(gnb, 'gnb')\n",
    "#y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "acc=accuracy_score(y_test,gnb_pred)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d, accuracy: %0.2f\"% (X_test.shape[0], (y_test != gnb_pred).sum(),acc))\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"% (X_test.shape[0], (y_test != gnb_pred).sum()))\n",
    "result_pd['gnb']=gnb_pred\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7  8  5  4  1  6 10  9  2  3]\n",
      "CPU times: user 248 ms, sys: 4 ms, total: 252 ms\n",
      "Wall time: 249 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lr</th>\n",
       "      <th>gb_C</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgbt</th>\n",
       "      <th>xgbtc</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>rf</th>\n",
       "      <th>gbtR</th>\n",
       "      <th>knn</th>\n",
       "      <th>SVC</th>\n",
       "      <th>logRe</th>\n",
       "      <th>logRe_mulabel_pred</th>\n",
       "      <th>GridSearch_best</th>\n",
       "      <th>RandSearch_best</th>\n",
       "      <th>adb</th>\n",
       "      <th>DTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20188</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20189</th>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191</th>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20193 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin   lr  gb_C  svr  xgbt  xgbtc  lgbm   rf  gbtR  knn  SVC  logRe  \\\n",
       "0           7  6.0   6.0  5.0   9.0      9     9  8.0   6.0  7.0    4      4   \n",
       "1          10  6.0   6.0  7.0   7.0      8     7  8.0   7.0  7.0    7      7   \n",
       "2           5  5.0   5.0  6.0   1.0      5     9  6.0   7.0  5.0    1      1   \n",
       "3           4  6.0   6.0  4.0   4.0      4     4  4.0   3.0  3.0    4      4   \n",
       "4           5  6.0   6.0  5.0   5.0      5     5  7.0   7.0  7.0    4      4   \n",
       "...       ...  ...   ...  ...   ...    ...   ...  ...   ...  ...  ...    ...   \n",
       "20188       1  6.0   6.0  5.0   4.0      1     1  1.0   5.0  2.0    1      8   \n",
       "20189       8  6.0   6.0  7.0   7.0      8     8  8.0   8.0  8.0    7      4   \n",
       "20190      10  6.0   6.0  7.0   9.0      9     9  9.0   7.0  8.0    9     10   \n",
       "20191       9  6.0   6.0  7.0   9.0      9     5  9.0   7.0  8.0    9     10   \n",
       "20192       7  5.0   5.0  6.0   8.0      7     7  7.0   7.0  6.0    1      5   \n",
       "\n",
       "       logRe_mulabel_pred  GridSearch_best  RandSearch_best  adb  DTree  \n",
       "0                       4              7.0              7.0    4      7  \n",
       "1                       7              8.0              9.0    7      8  \n",
       "2                       1              7.0              5.0    1      5  \n",
       "3                       4              4.0              4.0    4      4  \n",
       "4                       4              7.0              7.0    4      5  \n",
       "...                   ...              ...              ...  ...    ...  \n",
       "20188                   8              2.0              1.0    1      1  \n",
       "20189                   4              7.0              8.0    7      8  \n",
       "20190                  10              8.0              9.0    6      9  \n",
       "20191                  10              6.0              9.0    6      9  \n",
       "20192                   5              6.0              7.0    7      7  \n",
       "\n",
       "[20193 rows x 17 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf_pred = fit_and_predict(clf, 'DTree')\n",
    "\n",
    "t1 = time()\n",
    "clf_t=t1-t0\n",
    "\n",
    "result_pd['DTree']=clf_pred\n",
    "print(result_pd['DTree'].unique())\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40366,)\n",
      "(40366, 19)\n",
      "CPU times: user 68 ms, sys: 60 ms, total: 128 ms\n",
      "Wall time: 24.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr_pred= fit_and_predict(lr,'lr_sk')\n",
    "lr_mae,lr_mse,lr_r2_score=evaluate(y_test, lr_pred)\n",
    "\n",
    "#lr_mae,lr_mse,lr_r2_score,lr_max_error,lr_pred = fit_and_evaluate(lr,'lr')\n",
    "t1 = time()\n",
    "lr_t=t1-t0\n",
    "\n",
    "print(lr_pred.shape)\n",
    "result_pd['lr']=lr_pred\n",
    "print(result_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.96 s, sys: 8 ms, total: 8.97 s\n",
      "Wall time: 8.97 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lr</th>\n",
       "      <th>gb_C</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgbt</th>\n",
       "      <th>xgbtc</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>rf</th>\n",
       "      <th>gbtR</th>\n",
       "      <th>knn</th>\n",
       "      <th>SVC</th>\n",
       "      <th>logRe</th>\n",
       "      <th>logRe_mulabel_pred</th>\n",
       "      <th>GridSearch_best</th>\n",
       "      <th>RandSearch_best</th>\n",
       "      <th>adb</th>\n",
       "      <th>DTree</th>\n",
       "      <th>gtbc_best</th>\n",
       "      <th>gtbc_grid_best</th>\n",
       "      <th>gbc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20188</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20189</th>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191</th>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20193 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin   lr  gb_C  svr  xgbt  xgbtc  lgbm   rf  gbtR  knn  SVC  logRe  \\\n",
       "0           7  6.0   6.0  5.0   9.0      9     9  8.0   6.0  7.0    4      4   \n",
       "1          10  6.0   6.0  7.0   7.0      8     7  8.0   7.0  7.0    7      7   \n",
       "2           5  5.0   5.0  6.0   1.0      5     9  6.0   7.0  5.0    1      1   \n",
       "3           4  6.0   6.0  4.0   4.0      4     4  4.0   3.0  3.0    4      4   \n",
       "4           5  6.0   6.0  5.0   5.0      5     5  7.0   7.0  7.0    4      4   \n",
       "...       ...  ...   ...  ...   ...    ...   ...  ...   ...  ...  ...    ...   \n",
       "20188       1  6.0   6.0  5.0   4.0      1     1  1.0   5.0  2.0    1      8   \n",
       "20189       8  6.0   6.0  7.0   7.0      8     8  8.0   8.0  8.0    7      4   \n",
       "20190      10  6.0   6.0  7.0   9.0      9     9  9.0   7.0  8.0    9     10   \n",
       "20191       9  6.0   6.0  7.0   9.0      9     5  9.0   7.0  8.0    9     10   \n",
       "20192       7  5.0   5.0  6.0   8.0      7     7  7.0   7.0  6.0    1      5   \n",
       "\n",
       "       logRe_mulabel_pred  GridSearch_best  RandSearch_best  adb  DTree  \\\n",
       "0                       4              7.0              7.0    4      7   \n",
       "1                       7              8.0              9.0    7      8   \n",
       "2                       1              7.0              5.0    1      5   \n",
       "3                       4              4.0              4.0    4      4   \n",
       "4                       4              7.0              7.0    4      5   \n",
       "...                   ...              ...              ...  ...    ...   \n",
       "20188                   8              2.0              1.0    1      1   \n",
       "20189                   4              7.0              8.0    7      8   \n",
       "20190                  10              8.0              9.0    6      9   \n",
       "20191                  10              6.0              9.0    6      9   \n",
       "20192                   5              6.0              7.0    7      7   \n",
       "\n",
       "       gtbc_best  gtbc_grid_best  gbc  \n",
       "0              7               7    9  \n",
       "1              7               7    7  \n",
       "2              9               9   10  \n",
       "3              4               4    4  \n",
       "4              5               5    5  \n",
       "...          ...             ...  ...  \n",
       "20188          1               1    4  \n",
       "20189          7               8    7  \n",
       "20190          9               9    9  \n",
       "20191          9               9    9  \n",
       "20192          7               7    5  \n",
       "\n",
       "[20193 rows x 20 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "clf = GradientBoostingClassifier(n_estimators=10, \n",
    "                                 learning_rate=0.1, \n",
    "                                 max_depth=5)\n",
    "\n",
    "gbc_pred= fit_and_predict(clf,'gbc')\n",
    "#gbc_mae,gbc_mse,gbc_r2_score=evaluate(y_test, gbc_pred)\n",
    "\n",
    "t1 = time()\n",
    "gbc_t=t1-t0\n",
    "result_pd['gbc']=gbc_pred\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lr</th>\n",
       "      <th>gb_C</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgbt</th>\n",
       "      <th>xgbtc</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>rf</th>\n",
       "      <th>gbtR</th>\n",
       "      <th>knn</th>\n",
       "      <th>SVC</th>\n",
       "      <th>logRe</th>\n",
       "      <th>logRe_mulabel_pred</th>\n",
       "      <th>GridSearch_best</th>\n",
       "      <th>RandSearch_best</th>\n",
       "      <th>adb</th>\n",
       "      <th>DTree</th>\n",
       "      <th>gtbc_best</th>\n",
       "      <th>gtbc_grid_best</th>\n",
       "      <th>gbc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20188</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20189</th>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191</th>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20193 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin   lr  gb_C  svr  xgbt  xgbtc  lgbm   rf  gbtR  knn  SVC  logRe  \\\n",
       "0           7  6.0   6.0  5.0   9.0      9     9  8.0   6.0  7.0    4      4   \n",
       "1          10  6.0   6.0  7.0   7.0      8     7  8.0   7.0  7.0    7      7   \n",
       "2           5  5.0   5.0  6.0   1.0      5     9  6.0   7.0  5.0    1      1   \n",
       "3           4  6.0   6.0  4.0   4.0      4     4  4.0   3.0  3.0    4      4   \n",
       "4           5  6.0   6.0  5.0   5.0      5     5  7.0   7.0  7.0    4      4   \n",
       "...       ...  ...   ...  ...   ...    ...   ...  ...   ...  ...  ...    ...   \n",
       "20188       1  6.0   6.0  5.0   4.0      1     1  1.0   5.0  2.0    1      8   \n",
       "20189       8  6.0   6.0  7.0   7.0      8     8  8.0   8.0  8.0    7      4   \n",
       "20190      10  6.0   6.0  7.0   9.0      9     9  9.0   7.0  8.0    9     10   \n",
       "20191       9  6.0   6.0  7.0   9.0      9     5  9.0   7.0  8.0    9     10   \n",
       "20192       7  5.0   5.0  6.0   8.0      7     7  7.0   7.0  6.0    1      5   \n",
       "\n",
       "       logRe_mulabel_pred  GridSearch_best  RandSearch_best  adb  DTree  \\\n",
       "0                       4              7.0              7.0    4      7   \n",
       "1                       7              8.0              9.0    7      8   \n",
       "2                       1              7.0              5.0    1      5   \n",
       "3                       4              4.0              4.0    4      4   \n",
       "4                       4              7.0              7.0    4      5   \n",
       "...                   ...              ...              ...  ...    ...   \n",
       "20188                   8              2.0              1.0    1      1   \n",
       "20189                   4              7.0              8.0    7      8   \n",
       "20190                  10              8.0              9.0    6      9   \n",
       "20191                  10              6.0              9.0    6      9   \n",
       "20192                   5              6.0              7.0    7      7   \n",
       "\n",
       "       gtbc_best  gtbc_grid_best  gbc  \n",
       "0              7               7    9  \n",
       "1              7               7    7  \n",
       "2              9               9   10  \n",
       "3              4               4    4  \n",
       "4              5               5    5  \n",
       "...          ...             ...  ...  \n",
       "20188          1               1    4  \n",
       "20189          7               8    7  \n",
       "20190          9               9    9  \n",
       "20191          9               9    9  \n",
       "20192          7               7    5  \n",
       "\n",
       "[20193 rows x 20 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "#svm = SVR(C = 1000, gamma = 0.1)\n",
    "svr = SVR(C = 1, gamma = 0.15,cache_size=500)\n",
    "svr_pred= fit_and_predict(svr,'svr')\n",
    "svr_mae,svr_mse,svr_r2_score=evaluate(y_test, svr_pred)\n",
    "\n",
    "t1 = time()\n",
    "svr_t=t1-t0\n",
    "result_pd['svr']=svr_pred\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "#model.fit(X, y)\n",
    "    # Make predictions and evalute\n",
    "#model_pred = model.predict(X_test)\n",
    "\n",
    "# read data into Xgboost DMatrix format\n",
    "#train_labels=train_labels.copy()-1\n",
    "#test_labels=test_labels.copy()-1\n",
    "featurename=train_features.drop('new_tsp', axis=1).columns.values\n",
    "print(featurename)\n",
    "if pre_targets=='location_no':\n",
    "    y=y-1\n",
    "    y_test=y_test-1\n",
    "    \n",
    "dtrain = xgb.DMatrix(X, label=y,feature_names=featurename)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test,feature_names=featurename)\n",
    "#dtrain = xgb.DMatrix(Xtrain, label=ytrain, feature_names=feature_names)\n",
    "\n",
    "#feature_names=feature_names\n",
    "# specify parameters via map\n",
    "params = {\n",
    "    'booster':'gbtree',     #  tree-based models\n",
    "    'objective': 'multi:softmax', \n",
    "    'num_class':10, \n",
    "    'eta': 0.1,             # Same to learning rate\n",
    "    'gamma':0,              # Similar to min_impurity_decrease in GBDT\n",
    "    'alpha': 0,             # L1 regularization term on weight (analogous to Lasso regression)\n",
    "    'lambda': 2,            # L2 regularization term on weights (analogous to Ridge regression)\n",
    "    'max_depth': 5,         # Same as the max_depth of GBDT\n",
    "    'subsample': 1,         # Same as the subsample of GBDT\n",
    "    'colsample_bytree': 1,  # Similar to max_features in GBM\n",
    "    'min_child_weight': 1,  # minimum sum of instance weight (Hessian) needed in a child\n",
    "    'nthread':1,            # default to maximum number of threads available if not set\n",
    "}\n",
    "num_round = 10\n",
    "\n",
    "# start training\n",
    "#t0 = time()\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "# get prediction and evaluate\n",
    "xgb_pred = bst.predict(dtest)\n",
    "\n",
    "t1 = time()\n",
    "xgb_t=t1-t0\n",
    "print(xgb_t)\n",
    "if pre_targets=='location_no':\n",
    "    result_pd['xgbt']=xgb_pred+1\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbt_cmodel = XGBClassifier()\n",
    "xgbt_cpred=fit_and_predict(xgbt_cmodel,'xgbtc')\n",
    "result_pd['xgbtc']=xgbt_cpred\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "# print(xgbt_cmodel.feature_importances_)\n",
    "# # plot\n",
    "# plt.bar(range(1,len(xgbt_cmodel.feature_importances_)+1,1), xgbt_cmodel.feature_importances_)\n",
    "# plt.show()\n",
    "importance = pd.DataFrame(xgbt_cmodel.feature_importances_,index=featurename, columns=['importance'])\n",
    "print(importance)\n",
    "\n",
    "#xgb.plot_importance(xgbt_cmodel, max_num_features=10)\n",
    "\n",
    "importance.sort_values(\"importance\", ascending = True).plot( y =\"importance\", kind = 'barh', color = 'green', edgecolor = 'black')\n",
    "plt.ylabel('');\n",
    "plt.yticks(size = 14);\n",
    "plt.xlabel(\"importance\"); plt.xticks(size = 14)\n",
    "plt.title('Model Comparison on importance', size = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install lightgbm --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((train_labels-1).unique())\n",
    "# print((test_labels-1).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2 -1  3  0]\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 47116, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score -1.552430\n",
      "[LightGBM] [Info] Start training from score -2.106025\n",
      "[LightGBM] [Info] Start training from score -1.560583\n",
      "[LightGBM] [Info] Start training from score -1.712311\n",
      "[LightGBM] [Info] Start training from score -1.287048\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "print((train_labels-1).unique())\n",
    "# train_data = lgb.Dataset(X, label=y-1,feature_name=featurename)\n",
    "# test_data = lgb.Dataset(X_test, label=y_test-1)\n",
    "featurename=train_features.drop('new_tsp', axis=1).columns.values\n",
    "#print(X_test)\n",
    "\n",
    "if pre_targets=='location_no':\n",
    "    y=y-1\n",
    "    y_test=y_test-1\n",
    "    \n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "# train_data = lgb.Dataset(train_features.drop('new_tsp', axis=1), label=y-1)\n",
    "# test_data = lgb.Dataset(test_features.drop('new_tsp', axis=1), label=y_test-1)\n",
    "\n",
    "# dtrain = xgb.DMatrix(train_features.drop('new_tsp', axis=1), label=train_labels-1,feature_names=featurename)\n",
    "# dtest = xgb.DMatrix(test_features.drop('new_tsp', axis=1), label=test_labels-1)\n",
    "\n",
    "#best_para=gs.best_params_\n",
    "best_para={'colsample_bytree': 0.8754369812451743, 'min_child_samples': 372, 'min_child_weight': 10.0, 'num_leaves': 44, 'reg_alpha': 1, 'reg_lambda': 0, 'subsample': 0.568664015245299} \n",
    "\n",
    "\n",
    "# specify parameters via map\n",
    "# params = {\n",
    "#     'num_leaves':31,                # Same to max_leaf_nodes in GBDT, but GBDT's default value is None\n",
    "#     'max_depth': -1,                # Same to max_depth of xgboost\n",
    "#     'tree_learner': 'serial', \n",
    "#     'application':'multiclass',     # Same to objective of xgboost\n",
    "#     'num_class':10,                 # Same to num_class of xgboost\n",
    "#     'learning_rate': 0.1,           # Same to eta of xgboost\n",
    "#     'min_split_gain': 0,            # Same to gamma of xgboost\n",
    "#     'lambda_l1': 0,                 # Same to alpha of xgboost\n",
    "#     'lambda_l2': 0,                 # Same to lambda of xgboost\n",
    "#     'min_data_in_leaf': 20,         # Same to min_samples_leaf of GBDT\n",
    "#     'bagging_fraction': 1.0,        # Same to subsample of xgboost\n",
    "#     'bagging_freq': 0,\n",
    "#     'bagging_seed': 0,\n",
    "#     'feature_fraction': 1.0,         # Same to colsample_bytree of xgboost\n",
    "#     'feature_fraction_seed': 2,\n",
    "#     'min_sum_hessian_in_leaf': 1e-3, # Same to min_child_weight of xgboost\n",
    "#     'num_threads': 1\n",
    "# }\n",
    "num_round = 10\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "bst = lgb.train(params, train_data, num_round)\n",
    "\n",
    "# get prediction and evaluate\n",
    "#ypred_onehot = bst.predict(X_test)\n",
    "ypred_onehot = bst.predict(X_test)\n",
    "\n",
    "lgbm_pred = []\n",
    "for i in range(len(ypred_onehot)):\n",
    "    lgbm_pred.append(ypred_onehot[i].argmax())\n",
    "    \n",
    "t1 = time()\n",
    "lgbm_t=t1-t0\n",
    "#accuracy = np.sum(ypred == ytest) / len(ypred)\n",
    "#print('Test accuracy = {}'.format(accuracy))\n",
    "#print(lgbm_pred)\n",
    "result_pd['lgbm']=lgbm_pred\n",
    "if pre_targets=='location_no':\n",
    "    result_pd['lgbm']=result_pd['lgbm']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lr</th>\n",
       "      <th>gb_C</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgbt</th>\n",
       "      <th>xgbtc</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>rf</th>\n",
       "      <th>gbtR</th>\n",
       "      <th>knn</th>\n",
       "      <th>SVC</th>\n",
       "      <th>logRe</th>\n",
       "      <th>logRe_mulabel_pred</th>\n",
       "      <th>GridSearch_best</th>\n",
       "      <th>RandSearch_best</th>\n",
       "      <th>adb</th>\n",
       "      <th>DTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20188</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20189</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20190</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20192</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20193 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin   lr  gb_C  svr  xgbt  xgbtc  lgbm   rf  gbtR  knn  SVC  logRe  \\\n",
       "0           3  2.0   2.0  2.0   1.0      3     4  3.0   2.0  3.0    4      1   \n",
       "1           4  2.0   2.0  3.0   4.0      3     3  3.0   3.0  3.0    3      3   \n",
       "2           2  2.0   2.0  2.0   5.0      2     4  2.0   3.0  2.0    4      4   \n",
       "3           1  2.0   2.0  1.0   2.0      1     1  1.0   1.0  1.0    4      1   \n",
       "4           2  2.0   2.0  2.0   3.0      2     2  3.0   3.0  3.0    4      1   \n",
       "...       ...  ...   ...  ...   ...    ...   ...  ...   ...  ...  ...    ...   \n",
       "20188       0  2.0   2.0  2.0   1.0      0     0  0.0   1.0  0.0    0      3   \n",
       "20189       3  2.0   2.0  3.0   4.0      3     3  3.0   3.0  3.0    3      3   \n",
       "20190       4  2.0   2.0  3.0   5.0      4     4  4.0   3.0  3.0    4      4   \n",
       "20191       4  2.0   2.0  3.0   3.0      4     2  4.0   3.0  3.0    4      4   \n",
       "20192       3  2.0   2.0  2.0   3.0      3     2  3.0   2.0  2.0    4      2   \n",
       "\n",
       "       logRe_mulabel_pred  GridSearch_best  RandSearch_best  adb  DTree  \n",
       "0                       1              2.0              3.0    4      4  \n",
       "1                       3              3.0              3.0    3      3  \n",
       "2                       4              3.0              2.0    4      4  \n",
       "3                       1              1.0              1.0    1      1  \n",
       "4                       1              3.0              3.0    1      1  \n",
       "...                   ...              ...              ...  ...    ...  \n",
       "20188                   3              1.0              0.0    1      1  \n",
       "20189                   3              3.0              3.0    1      1  \n",
       "20190                   4              2.0              4.0    4      4  \n",
       "20191                   4              3.0              4.0    4      4  \n",
       "20192                   2              3.0              3.0    3      3  \n",
       "\n",
       "[20193 rows x 17 columns]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 14.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score reached: 0.9162280711534058 with params: {'colsample_bytree': 0.8754369812451743, 'min_child_samples': 372, 'min_child_weight': 10.0, 'num_leaves': 44, 'reg_alpha': 1, 'reg_lambda': 0, 'subsample': 0.568664015245299} \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "n_HP_points_to_test=10\n",
    "\n",
    "# fit_params={\"early_stopping_rounds\":30, \n",
    "#             #\"eval_metric\" : 'mae', \n",
    "#             \"eval_set\" : [(X_test,y_test)],\n",
    "#             'eval_names': ['valid'],\n",
    "#             #'objective' : 'multiclass',\n",
    "#             'metrics' : {'val_f1'},\n",
    "#             #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "#             'verbose': 100,\n",
    "#             'categorical_feature': 'auto'}\n",
    "\n",
    "param_test ={'num_leaves': sp_randint(6, 20), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)\n",
    "\n",
    "gs.fit(X, y)\n",
    "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
      "       'param_colsample_bytree', 'param_min_child_samples',\n",
      "       'param_min_child_weight', 'param_num_leaves', 'param_reg_alpha',\n",
      "       'param_reg_lambda', 'param_subsample', 'params', 'split0_test_score',\n",
      "       'split1_test_score', 'split2_test_score', 'mean_test_score',\n",
      "       'std_test_score', 'rank_test_score'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_min_child_samples</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_num_leaves</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.627120</td>\n",
       "      <td>0.193745</td>\n",
       "      <td>19.229886</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>0.950124</td>\n",
       "      <td>301</td>\n",
       "      <td>0.1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.932647</td>\n",
       "      <td>{'colsample_bytree': 0.9501241488957805, 'min_...</td>\n",
       "      <td>0.910225</td>\n",
       "      <td>0.914995</td>\n",
       "      <td>0.912894</td>\n",
       "      <td>0.912705</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.836639</td>\n",
       "      <td>0.415595</td>\n",
       "      <td>1.768390</td>\n",
       "      <td>0.130058</td>\n",
       "      <td>0.973167</td>\n",
       "      <td>171</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.557573</td>\n",
       "      <td>{'colsample_bytree': 0.9731668400523877, 'min_...</td>\n",
       "      <td>0.856170</td>\n",
       "      <td>0.856097</td>\n",
       "      <td>0.853040</td>\n",
       "      <td>0.855102</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.135651</td>\n",
       "      <td>0.209104</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.775604</td>\n",
       "      <td>424</td>\n",
       "      <td>10000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.934866</td>\n",
       "      <td>{'colsample_bytree': 0.7756038066515227, 'min_...</td>\n",
       "      <td>0.276073</td>\n",
       "      <td>0.276090</td>\n",
       "      <td>0.276090</td>\n",
       "      <td>0.276085</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.011510</td>\n",
       "      <td>0.089696</td>\n",
       "      <td>7.636462</td>\n",
       "      <td>0.036750</td>\n",
       "      <td>0.819604</td>\n",
       "      <td>422</td>\n",
       "      <td>1000</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.664986</td>\n",
       "      <td>{'colsample_bytree': 0.8196039247657971, 'min_...</td>\n",
       "      <td>0.645549</td>\n",
       "      <td>0.651449</td>\n",
       "      <td>0.645654</td>\n",
       "      <td>0.647551</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.055953</td>\n",
       "      <td>0.074242</td>\n",
       "      <td>0.427650</td>\n",
       "      <td>0.066786</td>\n",
       "      <td>0.806323</td>\n",
       "      <td>491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.656442</td>\n",
       "      <td>{'colsample_bytree': 0.8063232376017694, 'min_...</td>\n",
       "      <td>0.650070</td>\n",
       "      <td>0.651130</td>\n",
       "      <td>0.648965</td>\n",
       "      <td>0.650055</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.525365</td>\n",
       "      <td>0.072561</td>\n",
       "      <td>10.413088</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>0.687909</td>\n",
       "      <td>163</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.677506</td>\n",
       "      <td>{'colsample_bytree': 0.6879091728281055, 'min_...</td>\n",
       "      <td>0.905450</td>\n",
       "      <td>0.908437</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.907038</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.676679</td>\n",
       "      <td>1.076466</td>\n",
       "      <td>9.296018</td>\n",
       "      <td>0.407787</td>\n",
       "      <td>0.875437</td>\n",
       "      <td>372</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568664</td>\n",
       "      <td>{'colsample_bytree': 0.8754369812451743, 'min_...</td>\n",
       "      <td>0.914428</td>\n",
       "      <td>0.916714</td>\n",
       "      <td>0.917542</td>\n",
       "      <td>0.916228</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27.324565</td>\n",
       "      <td>0.129707</td>\n",
       "      <td>16.254645</td>\n",
       "      <td>0.051637</td>\n",
       "      <td>0.404829</td>\n",
       "      <td>350</td>\n",
       "      <td>0.001</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.927402</td>\n",
       "      <td>{'colsample_bytree': 0.404828563763895, 'min_c...</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.902006</td>\n",
       "      <td>0.903088</td>\n",
       "      <td>0.901392</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.520430</td>\n",
       "      <td>0.565263</td>\n",
       "      <td>12.623569</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.727199</td>\n",
       "      <td>212</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.447821</td>\n",
       "      <td>{'colsample_bytree': 0.7271985991098294, 'min_...</td>\n",
       "      <td>0.912263</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.913149</td>\n",
       "      <td>0.912705</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.739559</td>\n",
       "      <td>1.397795</td>\n",
       "      <td>9.463101</td>\n",
       "      <td>0.074575</td>\n",
       "      <td>0.556075</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893911</td>\n",
       "      <td>{'colsample_bytree': 0.55607546409401, 'min_ch...</td>\n",
       "      <td>0.900484</td>\n",
       "      <td>0.903789</td>\n",
       "      <td>0.904935</td>\n",
       "      <td>0.903069</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      37.627120      0.193745        19.229886        0.118057   \n",
       "1      15.836639      0.415595         1.768390        0.130058   \n",
       "2      10.135651      0.209104         0.002771        0.000042   \n",
       "3      21.011510      0.089696         7.636462        0.036750   \n",
       "4      11.055953      0.074242         0.427650        0.066786   \n",
       "5      20.525365      0.072561        10.413088        0.012762   \n",
       "6      24.676679      1.076466         9.296018        0.407787   \n",
       "7      27.324565      0.129707        16.254645        0.051637   \n",
       "8      23.520430      0.565263        12.623569        0.030124   \n",
       "9      18.739559      1.397795         9.463101        0.074575   \n",
       "\n",
       "  param_colsample_bytree param_min_child_samples param_min_child_weight  \\\n",
       "0               0.950124                     301                    0.1   \n",
       "1               0.973167                     171                  1e-05   \n",
       "2               0.775604                     424                  10000   \n",
       "3               0.819604                     422                   1000   \n",
       "4               0.806323                     491                    0.1   \n",
       "5               0.687909                     163                     10   \n",
       "6               0.875437                     372                     10   \n",
       "7               0.404829                     350                  0.001   \n",
       "8               0.727199                     212                   0.01   \n",
       "9               0.556075                     103                     10   \n",
       "\n",
       "  param_num_leaves param_reg_alpha param_reg_lambda param_subsample  \\\n",
       "0               28               0              100        0.932647   \n",
       "1               41              10              100        0.557573   \n",
       "2               30               0              100        0.934866   \n",
       "3               28               2                5        0.664986   \n",
       "4               24             100               20        0.656442   \n",
       "5               10               1              0.1        0.677506   \n",
       "6               44               1                0        0.568664   \n",
       "7               36               1                5        0.927402   \n",
       "8               13             0.1                5        0.447821   \n",
       "9               22               2                1        0.893911   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'colsample_bytree': 0.9501241488957805, 'min_...           0.910225   \n",
       "1  {'colsample_bytree': 0.9731668400523877, 'min_...           0.856170   \n",
       "2  {'colsample_bytree': 0.7756038066515227, 'min_...           0.276073   \n",
       "3  {'colsample_bytree': 0.8196039247657971, 'min_...           0.645549   \n",
       "4  {'colsample_bytree': 0.8063232376017694, 'min_...           0.650070   \n",
       "5  {'colsample_bytree': 0.6879091728281055, 'min_...           0.905450   \n",
       "6  {'colsample_bytree': 0.8754369812451743, 'min_...           0.914428   \n",
       "7  {'colsample_bytree': 0.404828563763895, 'min_c...           0.899083   \n",
       "8  {'colsample_bytree': 0.7271985991098294, 'min_...           0.912263   \n",
       "9  {'colsample_bytree': 0.55607546409401, 'min_ch...           0.900484   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.914995           0.912894         0.912705        0.001952   \n",
       "1           0.856097           0.853040         0.855102        0.001458   \n",
       "2           0.276090           0.276090         0.276085        0.000008   \n",
       "3           0.651449           0.645654         0.647551        0.002757   \n",
       "4           0.651130           0.648965         0.650055        0.000884   \n",
       "5           0.908437           0.907227         0.907038        0.001227   \n",
       "6           0.916714           0.917542         0.916228        0.001317   \n",
       "7           0.902006           0.903088         0.901392        0.001692   \n",
       "8           0.912703           0.913149         0.912705        0.000362   \n",
       "9           0.903789           0.904935         0.903069        0.001887   \n",
       "\n",
       "   rank_test_score  \n",
       "0                2  \n",
       "1                7  \n",
       "2               10  \n",
       "3                9  \n",
       "4                8  \n",
       "5                4  \n",
       "6                1  \n",
       "7                6  \n",
       "8                3  \n",
       "9                5  "
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(gs.cv_results_)\n",
    "# Plot the training and testing error vs number of trees\n",
    "print(results.columns)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize(8, 8)\n",
    "sns.set_style(style='white')\n",
    "#plt.style.use('fivethirtyeight')\n",
    "plt.plot(results['param_num_leaves'], -1 * results['mean_test_score'], label = 'Testing Error')\n",
    "#plt.plot(results['param_n_estimators'], -1 * results['mean_train_score'], label = 'Training Error')\n",
    "plt.xlabel('Number of Trees'); plt.ylabel('Mean Abosolute Error'); plt.legend();\n",
    "plt.title('Performance vs Number of Trees');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_onehot = bst.predict(X_test)\n",
    "\n",
    "lgbm_pred = []\n",
    "for i in range(len(ypred_onehot)):\n",
    "    lgbm_pred.append(ypred_onehot[i].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB/result/sk_allData_resample_5m_location_no.csv\n"
     ]
    }
   ],
   "source": [
    "print(filepath)\n",
    "result_pd.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb.feature_importance()\n",
    "\n",
    "importance = pd.DataFrame(bst.feature_importance(),index=featurename, columns=['importance'])\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col,score in zip(train_features.columns,lgb.feature_importance):\n",
    "#     print(col,score)\n",
    "\n",
    "#lgb.plot_importance(bst)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "importance.sort_values(\"importance\", ascending = True).plot( y =\"importance\", kind = 'barh', color = 'green', edgecolor = 'black')\n",
    "plt.ylabel('');\n",
    "plt.yticks(size = 14);\n",
    "plt.xlabel(\"importance\"); plt.xticks(size = 14)\n",
    "plt.title('Model Comparison on importance', size = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "t0 = time()\n",
    "rf_sk = RandomForestRegressor(random_state=60)\n",
    "rf_pred= fit_and_predict(rf_sk ,'rf_sk')\n",
    "random_forest_mae,rf_mse,rf_r2_score=evaluate(y_test, rf_pred)\n",
    "\n",
    "t1 = time()\n",
    "rf_t=t1-t0\n",
    "\n",
    "result_pd['rf']=rf_pred\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "t0 = time()\n",
    "gradient_boosted = GradientBoostingRegressor(random_state=60)\n",
    "gb_pred= fit_and_predict(gradient_boosted,'gb_sk')\n",
    "gradient_boosted_mae, gb_mse,gb_r2_score=evaluate(y_test, gb_pred)\n",
    "t1 = time()\n",
    "gb_t=t1-t0\n",
    "\n",
    "result_pd['gbtR']=gb_pred\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit -n 1 -r 1\n",
    "t0 = time()\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "knn_pred = fit_and_predict(knn,'knn')\n",
    "\n",
    "knn_mae,knn_mse,knn_r2_score,=evaluate(y_test, knn_pred)\n",
    "\n",
    "t1 = time()\n",
    "knn_t=t1-t0\n",
    "\n",
    "result_pd['knn']=knn_pred\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t0 = time()\n",
    "#svm = SVR(C = 1000, gamma = 0.1)当C趋近于很小的时：意味着可以有更大的错误容忍\n",
    "svc = SVC(kernel='rbf', C = 0.1, gamma = 0.15)\n",
    "svc_pred= fit_and_predict(svc,'svc_sk')\n",
    "svc_mae,svc_mse,svc_r2_score=evaluate(y_test, svc_pred)\n",
    "#svc_mae,svc_mse,svc_r2_score,svc_max_error,svc_pred= fit_and_evaluate(svc,'svm')\n",
    "t1 = time()\n",
    "svc_t=t1-t0\n",
    "result_pd['SVC']=svc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "t0 = time()\n",
    "logRe = LogisticRegression(random_state=0)\n",
    "#logRe_pred, logRe_mae,logRe_mse,logRe_r2_score= fit_and_evaluate(logRe_cuml,'logRe_cmul_full')\n",
    "logRe_pred= fit_and_predict(logRe,'logRe_sk')\n",
    "logRe_mae,logRe_mse,logRe_r2_score=evaluate(y_test, logRe_pred)\n",
    "\n",
    "t1 = time()\n",
    "logRe_t=t1-t0\n",
    "\n",
    "result_pd['logRe']=logRe_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "labels=np.unique(y_test)\n",
    "labels.sort()\n",
    "\n",
    "testing_probs = pd.DataFrame(columns=labels)  \n",
    "\n",
    "models = {}\n",
    "\n",
    "for origin in labels:\n",
    "    model = LogisticRegression(random_state=0)\n",
    "    y_new = y == origin\n",
    "    model.fit(X, y_new)\n",
    "    testing_probs[origin] = model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "#testing_probs\n",
    "\n",
    "logRe_mulabel_pred =testing_probs.astype(float).idxmax(axis=1)\n",
    "\n",
    "result_pd['logRe_mulabel_pred']=logRe_mulabel_pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>adb</th>\n",
       "      <th>DTree</th>\n",
       "      <th>xgbtc</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>rf</th>\n",
       "      <th>knn</th>\n",
       "      <th>RandSearch_best</th>\n",
       "      <th>gb_C</th>\n",
       "      <th>gtbc_best</th>\n",
       "      <th>gtbc_grid_best</th>\n",
       "      <th>gbc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377203</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377205</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377206</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377207</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377208 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        origin  adb  DTree  xgbtc  lgbm    rf  knn  RandSearch_best  gb_C  \\\n",
       "0            5    9      5      5     5   5.0  4.0              5.0     5   \n",
       "1            9    9      9      9     9   9.0  8.0              9.0     9   \n",
       "2            1    1      1      1     1   1.0  0.0              1.0     1   \n",
       "3           10   10     10     10    10  10.0  9.0             10.0    10   \n",
       "4           10   10     10     10    10  10.0  9.0             10.0    10   \n",
       "...        ...  ...    ...    ...   ...   ...  ...              ...   ...   \n",
       "377203       4    4      4      4     4   4.0  3.0              4.0     4   \n",
       "377204       1    1      1      1     1   1.0  0.0              1.0     1   \n",
       "377205       4    4      4      4     4   4.0  3.0              4.0     4   \n",
       "377206       1    1      1      1     1   1.0  0.0              1.0     1   \n",
       "377207       7    9      7      7     7   7.0  6.0              7.0     7   \n",
       "\n",
       "        gtbc_best  gtbc_grid_best  gbc  \n",
       "0               5               5    5  \n",
       "1               9               9    9  \n",
       "2               1               1    1  \n",
       "3              10              10   10  \n",
       "4              10              10   10  \n",
       "...           ...             ...  ...  \n",
       "377203          4               4    4  \n",
       "377204          1               1    1  \n",
       "377205          4               4    4  \n",
       "377206          1               1    1  \n",
       "377207          7               7    7  \n",
       "\n",
       "[377208 rows x 12 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB/result/sk_allData_resample_20m_location_no.csv\n"
     ]
    }
   ],
   "source": [
    "#result_pd.to_csv('DB/result/sk_result_small_nolight.csv', index = False)\n",
    "print(filepath)\n",
    "result_pd.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without process lr MAE = 1.5687 svm MAE = 1.2624 random forest MAE = 0.4122 GB MAE = 0.9731  KNN MAE = 0.7794\n",
    "#without process lr MAE = 1.5356  svm MAE = 1.2192 random forest MAE = 0.3905 GB MAE =  0.9134  KNN MAE = 0.7670\n",
    "\n",
    "time= np.array([logRe_t, lr_t,svr_t,svc_t,rf_t, gb_t, knn_t,gbc_t,lgbm_t,xgb_t])\n",
    "timeT= pd.DataFrame({'model': ['LogiR','Linear Regression',\n",
    "                               'SVR','SVC', 'Random Forest', 'Gradient Boosted_Random',\n",
    "                               'K-Nearest Neighbors','Gradient Boosted Classifier',\n",
    "                               'lightbgm','xgboost'],\n",
    "                     'time':time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeTfilepath = 'DB/result/ExecT_'+resultfilename+'.csv'\n",
    "timeT.to_csv(timeTfilepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function to be optimized\n",
    "#loss = ['lad', 'huber']\n",
    "\n",
    "loss = ['deviance', 'exponential']\n",
    "# Number of trees used in the boosting process\n",
    "n_estimators = [10,20,50,80,100, 500, 900, 1100, 1500]\n",
    "\n",
    "# Maximum depth of each tree\n",
    "max_depth = [2, 3, 5, 10]\n",
    "\n",
    "# Minimum number of samples per leaf\n",
    "min_samples_leaf = [2, 4, 6, 8]\n",
    "\n",
    "# Minimum number of samples to split a node\n",
    "min_samples_split = [2, 4, 6, 10]\n",
    "\n",
    "# Maximum number of features to consider for making splits\n",
    "max_features = ['auto', 'sqrt', 'log2', None]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {'loss': loss,\n",
    "                       'n_estimators': n_estimators,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:  1.9min remaining:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'loss': ['deviance', 'exponential'],\n",
       "                                        'max_depth': [2, 3, 5, 10],\n",
       "                                        'max_features': ['auto', 'sqrt', 'log2',\n",
       "                                                         None],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 4, 6, 10],\n",
       "                                        'n_estimators': [10, 20, 50, 80, 100,\n",
       "                                                         500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model to use for hyperparameter tuning\n",
    "#model = GradientBoostingRegressor(random_state = 42)\n",
    "model=GradientBoostingClassifier(random_state = 42)\n",
    "# Set up the random search with 4-fold cross validation\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator=model,\n",
    "                               param_distributions=hyperparameter_grid,\n",
    "                               cv=4, n_iter=5, \n",
    "                               scoring = 'neg_mean_absolute_error',\n",
    "                               n_jobs = -1, verbose = 1, \n",
    "                               return_train_score = True,\n",
    "                               random_state=42)\n",
    "random_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rand=random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read saved model\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "if smaple!='1m':\n",
    "    filename='stored_model/rand_gtbc_best_1m.sav'\n",
    "    print(\"read saved model\")\n",
    "    gb_rand= pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80603, 8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtbc_best = np.round(gb_rand.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd['gtbc_best']=gtbc_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='rand_gtbc_best_'+smaple\n",
    "filename = 'stored_model/'+filename+'.sav'\n",
    "pickle.dump(gb_rand, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  24 | elapsed:  1.6min remaining: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'n_estimators': [100, 200, 300, 500, 1000, 1500]},\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search Object using the trees range and the random forest model\n",
    "model=GradientBoostingClassifier(random_state = 42)\n",
    "trees_grid = {'n_estimators': [100, 200, 300, 500, 1000,1500]}\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=trees_grid, cv = 4, \n",
    "                           scoring = 'neg_mean_absolute_error', verbose = 1,\n",
    "                           n_jobs = -1, return_train_score = True)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model=grid_search.best_estimator_\n",
    "gtbc_grid_best = np.round(grid_search_model.predict(X_test))\n",
    "result_pd['gtbc_grid_best']=gtbc_grid_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='grid_gtbc_best_'+smaple\n",
    "filename = 'stored_model/'+filename+'.sav'\n",
    "pickle.dump(grid_search_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113.071277</td>\n",
       "      <td>0.067072</td>\n",
       "      <td>0.681613</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>deviance</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 10,...</td>\n",
       "      <td>-0.833517</td>\n",
       "      <td>-0.845658</td>\n",
       "      <td>-0.847695</td>\n",
       "      <td>-0.822141</td>\n",
       "      <td>-0.837253</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.681269</td>\n",
       "      <td>-0.676939</td>\n",
       "      <td>-0.666723</td>\n",
       "      <td>-0.671081</td>\n",
       "      <td>-0.674003</td>\n",
       "      <td>0.005544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>407.827327</td>\n",
       "      <td>0.352814</td>\n",
       "      <td>0.897263</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>1100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>{'n_estimators': 1100, 'min_samples_split': 10...</td>\n",
       "      <td>-0.935563</td>\n",
       "      <td>-0.932847</td>\n",
       "      <td>-0.941761</td>\n",
       "      <td>-0.925206</td>\n",
       "      <td>-0.933844</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.788182</td>\n",
       "      <td>-0.777429</td>\n",
       "      <td>-0.761355</td>\n",
       "      <td>-0.770977</td>\n",
       "      <td>-0.774486</td>\n",
       "      <td>0.009759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_split': 10, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'n_estimators': 500, 'min_samples_split': 10,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1100</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>exponential</td>\n",
       "      <td>{'n_estimators': 1100, 'min_samples_split': 10...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     113.071277      0.067072         0.681613        0.003074   \n",
       "3     407.827327      0.352814         0.897263        0.004245   \n",
       "1       0.009088      0.000810         0.000000        0.000000   \n",
       "2       0.007475      0.001395         0.000000        0.000000   \n",
       "4       0.006949      0.001023         0.000000        0.000000   \n",
       "\n",
       "  param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                500                      10                      8   \n",
       "3               1100                      10                      2   \n",
       "1                 20                      10                      2   \n",
       "2                500                      10                      4   \n",
       "4               1100                      10                      6   \n",
       "\n",
       "  param_max_features param_max_depth   param_loss  \\\n",
       "0               sqrt               3     deviance   \n",
       "3               None               2     deviance   \n",
       "1               log2               5  exponential   \n",
       "2               sqrt               3  exponential   \n",
       "4               log2              10  exponential   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'n_estimators': 500, 'min_samples_split': 10,...          -0.833517   \n",
       "3  {'n_estimators': 1100, 'min_samples_split': 10...          -0.935563   \n",
       "1  {'n_estimators': 20, 'min_samples_split': 10, ...                NaN   \n",
       "2  {'n_estimators': 500, 'min_samples_split': 10,...                NaN   \n",
       "4  {'n_estimators': 1100, 'min_samples_split': 10...                NaN   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0          -0.845658          -0.847695          -0.822141        -0.837253   \n",
       "3          -0.932847          -0.941761          -0.925206        -0.933844   \n",
       "1                NaN                NaN                NaN              NaN   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "4                NaN                NaN                NaN              NaN   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.010271                1           -0.681269           -0.676939   \n",
       "3        0.005942                2           -0.788182           -0.777429   \n",
       "1             NaN                3                 NaN                 NaN   \n",
       "2             NaN                4                 NaN                 NaN   \n",
       "4             NaN                5                 NaN                 NaN   \n",
       "\n",
       "   split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0           -0.666723           -0.671081         -0.674003         0.005544  \n",
       "3           -0.761355           -0.770977         -0.774486         0.009759  \n",
       "1                 NaN                 NaN               NaN              NaN  \n",
       "2                 NaN                 NaN               NaN              NaN  \n",
       "4                 NaN                 NaN               NaN              NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all of the cv results and sort by the test performance\n",
    "random_results = pd.DataFrame(random_cv.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "random_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the results into a dataframe\n",
    "# results = pd.DataFrame(random_cv.cv_results_)\n",
    "# # Plot the training and testing error vs number of trees\n",
    "# figsize(8, 8)\n",
    "# sns.set_style(style='white')\n",
    "# #plt.style.use('fivethirtyeight')\n",
    "# plt.plot(results['param_n_estimators'], -1 * results['mean_test_score'], label = 'Testing Error')\n",
    "# plt.plot(results['param_n_estimators'], -1 * results['mean_train_score'], label = 'Training Error')\n",
    "# plt.xlabel('Number of Trees'); plt.ylabel('Mean Abosolute Error'); plt.legend();\n",
    "# plt.title('Performance vs Number of Trees');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalrand_model=random_cv.best_estimator_\n",
    "finalrand_model=GradientBoostingRegressor(loss='huber', max_depth=15, max_features='log2',\n",
    "                         min_samples_leaf=6, min_samples_split=10,\n",
    "                         n_estimators=1500, random_state=42)\n",
    "#GradientBoostingRegressor(loss='huber', max_depth=15, max_features='log2',\n",
    "#                         min_samples_leaf=6, min_samples_split=10,\n",
    "#                         n_estimators=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalrand_model=GradientBoostingRegressor(loss='huber', max_depth=15, max_features='log2',\n",
    "                         min_samples_leaf=6, min_samples_split=10,\n",
    "                         n_estimators=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of trees to evaluate\n",
    "trees_grid = {'n_estimators': [10,20,50,70,100, 150, 200, 250, 300, 350, 400, 450, 500,\n",
    "                               550, 600, 650, 700, 750, 800,1000,1100,1200,1500]}\n",
    "\n",
    "model = GradientBoostingRegressor(loss = 'lad', max_depth = 5,\n",
    "                                  min_samples_leaf = 6,\n",
    "                                  min_samples_split = 6,\n",
    "                                  max_features = None,\n",
    "                                  random_state = 42)\n",
    "\n",
    "# Grid Search Object using the trees range and the random forest model\n",
    "grid_search = GridSearchCV(estimator = model, param_grid=trees_grid, cv = 4, \n",
    "                           scoring = 'neg_mean_absolute_error', verbose = 1,\n",
    "                           n_jobs = -1, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results into a dataframe\n",
    "sns.set_style(style='white')\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# Plot the training and testing error vs number of trees\n",
    "figsize(8, 8)\n",
    "\n",
    "plt.plot(results['param_n_estimators'], -1 * results['mean_test_score'], label = 'Testing Error')\n",
    "plt.plot(results['param_n_estimators'], -1 * results['mean_train_score'], label = 'Training Error')\n",
    "plt.xlabel('Number of Trees'); plt.ylabel('Mean Abosolute Error'); plt.legend();\n",
    "plt.title('Performance vs Number of Trees');\n",
    "\n",
    "plt.savefig('./images/cf/randomgbt.png',dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('mean_test_score', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model\n",
    "default_model = GradientBoostingRegressor(random_state = 42)\n",
    "\n",
    "# Select the best model\n",
    "#final_model = grid_search.best_estimator_\n",
    "\n",
    "final_model = GradientBoostingRegressor(loss='lad', max_depth=5, min_samples_leaf=6,\n",
    "                         min_samples_split=6, n_estimators=1500,\n",
    "                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalrand_model=GradientBoostingRegressor(loss='huber', max_depth=15, max_features='log2',\n",
    "                         min_samples_leaf=6, min_samples_split=10,\n",
    "                         n_estimators=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "default_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "finalrand_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_RandSearch_pred = np.round(finalrand_model.predict(X_test))\n",
    "result_pd['RandSearch_best']=final_RandSearch_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_pred = np.round(default_model.predict(X_test))\n",
    "final_GridSearch_pred = np.round(final_model.predict(X_test))\n",
    "final_RandSearch_pred = np.round(finalrand_model.predict(X_test))\n",
    "\n",
    "\n",
    "result_pd['GridSearch_best']=final_GridSearch_pred\n",
    "result_pd['RandSearch_best']=final_RandSearch_pred\n",
    "\n",
    "print('Default model performance on the test set: MAE = %0.4f.' % mae(y_test, default_pred))\n",
    "print('Final Best Gridsearch model performance on the test set:   MAE = %0.4f.' % mae(y_test, final_GridSearch_pred))\n",
    "print('Final Best Random Search model performance on the test set:   MAE = %0.4f.' % mae(y_test, final_RandSearch_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath\n",
    "print(len(final_RandSearch_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd['origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>lr</th>\n",
       "      <th>gb_C</th>\n",
       "      <th>svr</th>\n",
       "      <th>xgbt</th>\n",
       "      <th>xgbtc</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>rf</th>\n",
       "      <th>gbtR</th>\n",
       "      <th>knn</th>\n",
       "      <th>SVC</th>\n",
       "      <th>logRe</th>\n",
       "      <th>logRe_mulabel_pred</th>\n",
       "      <th>GridSearch_best</th>\n",
       "      <th>RandSearch_best</th>\n",
       "      <th>adb</th>\n",
       "      <th>DTree</th>\n",
       "      <th>gbc</th>\n",
       "      <th>gtbc_best</th>\n",
       "      <th>gtbc_grid_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40361</th>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40362</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40363</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40364</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40365</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40366 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       origin   lr  gb_C  svr  xgbt  xgbtc  lgbm   rf  gbtR   knn  SVC  logRe  \\\n",
       "0           6  7.0   7.0  7.0   7.0      7     7  6.0   8.0   5.0    7      7   \n",
       "1          10  6.0   6.0  6.0  10.0     10    10  9.0  11.0   9.0    1     10   \n",
       "2           5  7.0   7.0  7.0   8.0      5     9  6.0   7.0   8.0    9      9   \n",
       "3           5  6.0   6.0  4.0   4.0      5     4  5.0   6.0   4.0    4      4   \n",
       "4           1  6.0   6.0  5.0   1.0      1     1  1.0   3.0   2.0    1      5   \n",
       "...       ...  ...   ...  ...   ...    ...   ...  ...   ...   ...  ...    ...   \n",
       "40361       8  6.0   6.0  7.0   8.0      8     8  8.0   8.0   8.0    4      4   \n",
       "40362       2  6.0   6.0  5.0   9.0      2     9  2.0   7.0   3.0    4      4   \n",
       "40363       9  5.0   5.0  5.0  10.0      9     9  9.0   8.0  10.0    1      5   \n",
       "40364       6  5.0   5.0  5.0   6.0      6     6  6.0   7.0   6.0    1      4   \n",
       "40365       3  5.0   5.0  5.0   1.0      3     3  3.0   4.0   2.0    1      1   \n",
       "\n",
       "       logRe_mulabel_pred  GridSearch_best  RandSearch_best  adb  DTree  gbc  \\\n",
       "0                       7              7.0              6.0    9      6    7   \n",
       "1                      10              9.0             10.0   10      9   10   \n",
       "2                       9              7.0              5.0    9      5    9   \n",
       "3                       4              4.0              5.0    4      3    4   \n",
       "4                       5              1.0              1.0    1      1    1   \n",
       "...                   ...              ...              ...  ...    ...  ...   \n",
       "40361                   4              8.0              8.0    4      8    8   \n",
       "40362                   4              8.0              2.0    4      2    9   \n",
       "40363                   5              8.0              9.0    2      9    5   \n",
       "40364                   4              6.0              6.0    6      6    6   \n",
       "40365                   1              4.0              3.0    1      3    1   \n",
       "\n",
       "       gtbc_best  gtbc_grid_best  \n",
       "0              9               5  \n",
       "1             10              10  \n",
       "2              5               5  \n",
       "3              5               5  \n",
       "4              1               1  \n",
       "...          ...             ...  \n",
       "40361          8               8  \n",
       "40362          9               2  \n",
       "40363          9               9  \n",
       "40364          6               6  \n",
       "40365          3               3  \n",
       "\n",
       "[40366 rows x 20 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pd.to_csv(filepath, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(8, 8)\n",
    "\n",
    "# Density plot of the final predictions and the test values\n",
    "# sns.kdeplot(final_GridSearch_pred, label = 'Grid Search Prediction Values')\n",
    "# sns.kdeplot(final_RandSearch_pred, label = 'Random Search Prediction Values')\n",
    "# sns.kdeplot(y_test, label = 'Test Values')\n",
    "\n",
    "model_comparison = pd.DataFrame({'Grid Search Prediction Values': final_GridSearch_pred,\n",
    "                                 'Random Search Prediction Values': final_RandSearch_pred, \n",
    "                                       'Test Value':y_test})\n",
    "\n",
    "sns.histplot(model_comparison, binwidth=1,alpha=0.5)\n",
    "\n",
    "# sns.histplot(final_GridSearch_pred, label = 'Grid Search Prediction Values')\n",
    "# sns.histplot(final_RandSearch_pred, label = 'Random Search Prediction Values')\n",
    "# sns.histplot(y_test, label = 'Test Values')\n",
    "\n",
    "    \n",
    "#plt.legend(bbox_to_anchor=(1, 0), loc='lower right', borderaxespad=1, fontsize=18)\n",
    "# Label the plot\n",
    "plt.xlabel('Location_No'); \n",
    "plt.ylabel('Density');\n",
    "plt.title('Test Values and Predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (6, 6)\n",
    "\n",
    "# Calculate the errors\n",
    "gridSearch_err = np.abs(final_GridSearch_pred - y_test)\n",
    "randSearch_err = np.abs(final_RandSearch_pred - y_test)\n",
    "\n",
    "model_comparison = pd.DataFrame({'Grid Search Prediction Errors': gridSearch_err,\n",
    "                                 'Random Search Prediction Errors': randSearch_err})\n",
    "\n",
    "# Plot the errors in a histogram\n",
    "sns.histplot(model_comparison, binwidth=1,alpha=0.5)\n",
    "\n",
    "# plt.hist(gridSearch_err, color = 'green', bins = 20,\n",
    "#          edgecolor = 'black',label = 'GridSearch result')\n",
    "\n",
    "# plt.hist(randSearch_err, color = 'blue', bins = 20,\n",
    "#          edgecolor = 'black',label = 'Random Search result')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 0), loc='lower right', borderaxespad=1, fontsize=18)\n",
    "\n",
    "\n",
    "plt.xlabel('Error values'); \n",
    "plt.ylabel('Count')\n",
    "plt.title('Error Distribution');\n",
    "#plt.title('Distribution of Residuals');\n",
    "plt.savefig('./images/boostingbest'+pre_targets+'.png',quality=100,dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(~np.isfinite(X)))\n",
    "print(np.where(~np.isfinite(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 386,
   "position": {
    "height": "40px",
    "left": "775px",
    "right": "20px",
    "top": "68px",
    "width": "658px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
