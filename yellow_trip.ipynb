{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cuda import LocalCUDACluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "train_features = cudf.read_csv('DB/new_data/training_features.csv')\n",
    "test_features=cudf.read_csv('DB/new_data/testing_features.csv')\n",
    "train_labels=cudf.read_csv('DB/new_data/training_labels.csv')\n",
    "test_labels=cudf.read_csv('DB/new_data/testing_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuml.test.utils import get_handle\n",
    "from cuml.ensemble import RandomForestRegressor as curfc\n",
    "from cuml.test.utils import get_handle\n",
    "\n",
    "X = np.asarray([[0,10],[0,20],[0,30],[0,40]], dtype=np.float32)\n",
    "y = np.asarray([0.0,1.0,2.0,3.0], dtype=np.float32)\n",
    "cuml_model = curfc(max_features=1.0, n_bins=2,\n",
    "                    split_algo=0, min_samples_leaf=1,\n",
    "                    min_samples_split=2,\n",
    "                    n_estimators=40, accuracy_metric='r2')\n",
    "\n",
    "cuml_model.fit(X,y)\n",
    "cuml_score = cuml_model.score(X,y)\n",
    "print(\"MSE score of cuml : \", cuml_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://qiita.com/shin_ishiguro/items/8f39aac45acc8363a42e\n",
    "\n",
    "import cudf\n",
    "import cuml\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'yellow_tripdata_2019-01.csv'\n",
    "cdf = cudf.read_csv(file_path) # cudf dataframeへのcsvファイル読み込み処理\n",
    "df = pd.read_csv(file_path) # pandas dataframeへのcsvファイル読み込み処理\n",
    "\n",
    "cdf = cdf.drop(columns='tpep_pickup_datetime')\n",
    "cdf = cdf.drop(columns='tpep_dropoff_datetime')\n",
    "cdf['pickup_date'] = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "cdf['dropoff_date'] = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "cdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_date = dt.datetime.strptime('2019-01-01', '%Y-%m-%d')\n",
    "cdf = cdf.query('pickup_date >= @search_date')\n",
    "search_date = dt.datetime.strptime('2019-01-05', '%Y-%m-%d')\n",
    "cdf = cdf.query('pickup_date < @search_date')\n",
    "cdf = cdf.reset_index(drop=True) # rapids0.11から inplace=Trueが使えるようになったようです。\n",
    "                                 # 0.10では使えませんでした\n",
    "\n",
    "cdf['pickup_date_day'] = cdf.pickup_date.dt.day\n",
    "cdf['pickup_date_weekday'] = cdf.pickup_date.dt.weekday\n",
    "cdf['pickup_date_hour'] = cdf.pickup_date.dt.hour\n",
    "cdf['dropoff_date_day'] = cdf.dropoff_date.dt.day\n",
    "cdf['dropoff_date_weekday'] = cdf.dropoff_date.dt.weekday\n",
    "cdf['dropoff_date_hour'] = cdf.dropoff_date.dt.hour\n",
    "\n",
    "le = cuml.preprocessing.LabelEncoder()\n",
    "cdf['store_and_fwd_flag'] = le.fit_transform(cdf.store_and_fwd_flag)\n",
    "# cumlは、sklearn同様カテゴリ変数のラベル特徴量化の前処理等もできます。\n",
    "\n",
    "cdf.congestion_surcharge.fillna(0, inplace=True)\n",
    "\n",
    "_columns = ['VendorID', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', \n",
    "            'DOLocationID', 'payment_type', \n",
    "            'pickup_date_day', 'pickup_date_weekday', 'pickup_date_hour', \n",
    "            'dropoff_date_day', 'dropoff_date_weekday', 'dropoff_date_hour']\n",
    "\n",
    "cdf = cudf.core.reshape.get_dummies(cdf, columns=_columns)\n",
    "# 様々なカテゴリ変数を1-hot特徴量に変換しています。\n",
    "\n",
    "for c in _columns:\n",
    "    if c in cdf.columns:\n",
    "        cdf = cdf.drop(columns=c)\n",
    "\n",
    "cdf.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask_cudf\n",
    "import dask_xgboost\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "\n",
    "import subprocess\n",
    "\n",
    "cmd = \"hostname --all-ip-addresses\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "IPADDR = str(output.decode()).split()[0]\n",
    "\n",
    "cluster = LocalCUDACluster(ip=IPADDR)\n",
    "client = Client(cluster) #processes=False)#\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "_npartitions = 8\n",
    "search_date = dt.datetime.strptime('2019-01-03', '%Y-%m-%d')\n",
    "# rapids0.10だとdask_dataframeでdropしようとすると、inplace周りにバグがあるため、エラーが起きる\n",
    "# このため、前処理で使えるメモリが減るが、cudf_dataframeの段階で前処理を済ませることにした\n",
    "\n",
    "cdf = cdf.drop(columns='dropoff_date')\n",
    "cdf_train = cdf.query('pickup_date < @search_date')\n",
    "cdf_test  = cdf.query('pickup_date >= @search_date')\n",
    "cdf_train = cdf_train.drop(columns='pickup_date')\n",
    "cdf_test  = cdf_test.drop(columns='pickup_date')\n",
    "\n",
    "ddf_train = dask_cudf.from_cudf(cdf_train, npartitions=_npartitions)\n",
    "y_train   = ddf_train[['tip_amount']]\n",
    "x_train   = ddf_train[ddf_train.columns.difference(['tip_amount'])]\n",
    "\n",
    "ddf_test  = dask_cudf.from_cudf(cdf_test, npartitions=_npartitions)\n",
    "y_test    = ddf_test[['tip_amount']]\n",
    "x_test    = ddf_test[ddf_test.columns.difference(['tip_amount'])]\n",
    "\n",
    "y_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_rounds': 100, # 学習ラウンド数です。多いほどデータセットにフィットします\n",
    "    'max_depth': 8,\n",
    "    'max_leaves': 2**8,\n",
    "    'n_gpus': 1, # 1つのGPUでは1つのプロセスで処理を行うため、n_gpusは1に固定して使うことが必須。\n",
    "                 # Dask側でMulti GPU Processの設定をしているので、ちゃんと複数で計算してくれています。\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'grow_policy': 'lossguide'\n",
    "}\n",
    "\n",
    "bst = dask_xgboost.train(client, params, x_train, y_train, num_boost_round=params['num_rounds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dask_xgboost.predict(client, bst, x_test)\n",
    "test = dask.dataframe.multi.concat([pred], axis=1)\n",
    "\n",
    "test['squared_error'] = (test[0] - y_test['tip_amount'])**2\n",
    "\n",
    "# 予測出力結果は、dask.dataframe.multi.concatを用いることで、\n",
    "# [dask_cudf.Series]から、dask_cudf.DataFrameに変換を行っています。\n",
    "\n",
    "rmse = np.sqrt(test.squared_error.mean().compute())\n",
    "print('rmse value:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv = 'T-drive/tdrive.txt'\n",
    "data = pd.read_csv(csv, header=None)\n",
    "data.columns = ['id', 'time', 'lon', 'lat']\n",
    "data0 = data[data['id'].isin(range(1,100))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "for i in range(1, 100):\n",
    "    point0 = np.array(data0[data0['id'] == i][['lon', 'lat']])\n",
    "    for j in range(1, 100):\n",
    "        point1 = np.array(data0[data0['id'] == j][['lon', 'lat']])\n",
    "        sklearn_distance = directed_hausdorff(point0, point1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "import numpy as np\n",
    "from concurrent import futures\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "future_list = []\n",
    "with futures.ProcessPoolExecutor(max_workers=16) as executor:\n",
    "    for i in range(1, 100):\n",
    "        point0 = np.array(data0[data0['id'] == i][['lon', 'lat']])\n",
    "        for j in range(1, 100):\n",
    "            point1 = np.array(data0[data0['id'] == j][['lon', 'lat']])\n",
    "            future = executor.submit(fn=directed_hausdorff, p0=point0, p1=point1)\n",
    "            future_list.append(future)\n",
    "    _ = futures.as_completed(fs=future_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cuspatial\n",
    "from cudf import Series\n",
    "\n",
    "# pandas, numpyからcudfに変換して利用します\n",
    "cnt = Series(data0.groupby('id').count().iloc[:,0])\n",
    "lon = Series(data0.lon)\n",
    "lat = Series(data0.lat)\n",
    "distance = cuspatial.directed_hausdorff_distance(lon, lat, cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
